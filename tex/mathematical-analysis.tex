
\documentclass[thmcnt=section, color=blue, 12pt]{my-elegantbook}

% Index page
\usepackage{imakeidx}
\makeindex[columns=2, intoc, options=-s index_style.ist]

% Title and author
\title{Mathematical Analysis}
\author{Isaac FEI}

% Reference file
\addbibresource{mathematical-analysis.bib} 

% Image of the book cover
\cover{cover}

\begin{document}

% Print title and cover page
\maketitle

%--------
% Preface
%--------

\frontmatter
\chapter*{Preface}

This book mainly follows the structure of \cite{apostolMathematicalAnalysisModern1974}.

%------------------------------

% Print table of contents
\tableofcontents
\mainmatter

%-------------------------------
% Main document starts from here
%-------------------------------

%==============================

\chapter{Point-Set Topology}

%==============================

\chapter{Functions of Bounded Variation and Rectifiable Curves}

%------------------------------ 

\section{Functions of Bounded Variation}

\begin{definition}
	Let $[a, b]$ be an interval.
	A set of points
	\begin{align*}
		P = \{ x_0, x_1, \dots, x_n \}
	\end{align*}
	satisfying
	\begin{align*}
		a = x_0 < x_1 < \cdots < x_n = b
	\end{align*}
	is called a \textbf{partition}\index{partition of an interval} of $[a, b]$.

	The interval $[x_{k-1}, x_k]$ is called the $k$-th subinterval of $P$,
	and we often write $\Delta x_k = x_k - x_{k-1}$.

	The collection of all partitions of $[a, b]$ is denoted by $\CALP [a, b]$.
\end{definition}


\begin{note}
	In mathematics texts, we have another definition of partitions,
	which states that a partition of a set $S$ is a collection of subsets of $S$
	such that they are disjoint and their union equals $S$.
	We should not confuse these two definitions.
\end{note}

\begin{definition}
	Let $f$ be a real-valued function on $[a, b]$.
	If $P = \{x_0, \dots x_n\}$ is a partition of $[a, b]$,
	write $\Delta f_k = f(x_k) - f(x_{k-1})$.
	If there exists a positive number $M$ such that
	\begin{align}
		\sum_{k=1}^n \abs{\Delta f_k} \leq M \label{eq:1}
	\end{align}
	for all partitions $P$ of $[a, b]$, then we say that $f$
	is \textbf{of bounded variation}\index{functions of bounded variation}
	on $[a, b]$.
\end{definition}

\begin{note}
	A geometric interpretation of the sum $\sum_{k=1}^n \abs{\Delta f_k}$
	is the total vertical length of several pieces of the function.
	Imagine a point moving along the curve of the function from the
	left to the right.
	If the partition gets finer and finer,
	then $\sum_{k=1}^n \abs{\Delta f_k}$
	will become the length of its journey projected on the $y$-axis.
	In fact, it is defined as the total variation as we shall introduce later.
\end{note}

Sometimes, it is convenient to denote the sum $\sum_{k=1}^n \abs{\Delta f_k}$
by the symbol
\begin{align*}
	v(P, f) := \sum_{k=1}^n \abs{\Delta f_k}
\end{align*}
We do not use the capital letter $V$ here for it is reserved for
the total variation.

A simple observation is that a function of bounded variation is also bounded.

\begin{proposition} \label{prop:2}
	Let $f$ be a function of bounded variation on $[a, b]$.
	Then $f$ is bounded on $[a, b]$.
\end{proposition}

\begin{proof}
	By definition, there exists $M > 0$ such that \eqref{eq:1} holds
	for any partitions of $[a, b]$.
	For any $x \in (a, b)$, consider the partition $P = \{a, x, b\}$.
	We have
	\begin{align*}
		\abs{f(x) - f(a)} + \abs{f(b) - f(x)} \leq M
	\end{align*}
	This implies that $\abs{f(x) - f(a)} \leq M$, which further
	implies $\abs{f(x)} \leq \abs{f(a)} + M$.
	Note that $x$ is arbitrarily chosen from $(a, b)$.
	Therefore, $f$ is indeed bounded on $[a, b]$.
\end{proof}

But a bounded function is not necessarily of bounded variation.

\begin{example} \label{eg:1}
	Consider the function
	\begin{align*}
		f(x) = \begin{cases}
			       \cos \frac{1}{x}, & x \in (0, 1] \\
			       0,                & x = 0
		       \end{cases}
	\end{align*}
	Its graph is shown in Figure~\ref{fig:1}.
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.6\textwidth]{figures/bounded-function-that-is-not-of-bounded-variation.png}
		\caption{Graph of the function $f(x) = \cos\frac{1}{x}$ for $x \in (0, 1]$ and $f(0) = 0$. It is bounded on $[0, 1]$ but not of bounded variation for it varies rapidly near $x=0$.}
		\label{fig:1}
	\end{figure}
	Clearly, this function is bounded by $1$.
	But intuitively, it is not of bounded variation since it varies rapidly
	near $x=0$.
	Let $P$ be a partition of $[0, 1]$ where each $x_k$ is given by
	\begin{align*}
		x_k = \begin{cases}
			      \frac{1}{(n-k) \pi}, & 1 \leq k \leq n-1 \\
			      0,                   & k = 0             \\
			      1,                   & k = n
		      \end{cases}
	\end{align*}
	For $k=1, \dots, n-1$, we have
	\begin{align*}
		f(x_k) = \cos ( (n-k) \pi ) \in \{-1, 1\}
	\end{align*}
	The function value is either $1$ or $-1$ and the sign alternates between
	each two consecutive points. Hence,
	\begin{align*}
		\sum_{k=1}^{n} \abs{\Delta f_k}
		\geq \sum_{k=2}^{n-1} \abs{\Delta f_k} = 2 (n - 2)
	\end{align*}
	As we increase the number of points in the partition, $\sum \abs{\Delta f_k}$
	will exceeds any given number.
	Therefore, $f$ is not of bounded variation on $[0, 1]$.
\end{example}

\begin{proposition} \label{prop:1}
	If $f$ is monotonic on $[a, b]$, then $f$ is of bounded variation on $[a, b]$.
\end{proposition}

\begin{proof}
	Assume $f$ is increasing.
	For any partition $P = \{x_0, \dots, x_n\}$ of $[a, b]$, we have
	\begin{align*}
		\sum_{k=1}^n \abs{\Delta f_k}
		= \sum_{k=1}^n (f(x_k) - f(x_{k-1}))
		= f(b) - f(a)
	\end{align*}
	Therefore, $f$ is of bounded variation on $[a, b]$.

	If $f$ is decreasing, then $-f$ is increasing.
	Applying what we have proved, we may conclude that $-f$ is of bounded variation.
	Hence, $f$ is also of bounded variation
	since $\sum \abs{\Delta (-f)_k} = \sum \abs{\Delta f_k}$.
\end{proof}

\begin{proposition} \label{prop:3}
	Suppose that $f$ is continuous on $[a, b]$ and the
	derivative $f^\prime$ exists in $(a, b)$.
	If $\abs{f^\prime(x)} \leq A$ for all $x \in (a, b)$,
	then $f$ is of bounded variation on $[a, b]$.
\end{proposition}

\begin{note}
	The assumption that $f$ being continuous on $[a, b]$,
	and $f^\prime$ exists in $(a, b)$ coincides with the mean value theorem.
	And indeed, it is the key of this proof.
\end{note}

\begin{proof}
	Let $P = \{x_0, \dots, x_n\}$ be a partition of $[a, b]$.
	By the mean value theorem, there exists $t_k \in (x_{k-1}, x_k)$
	for all $k=1, \dots, n$ such that
	\begin{align*}
		f(x_k) - f(x_{k-1}) = f^\prime(t_k) (x_k - x_{k-1})
	\end{align*}
	It then follows that
	\begin{align*}
		\sum_{k=1}^n \abs{\Delta f_k}
		 & = \sum_{k=1}^n \abs{f^\prime(t_k)} (x_k - x_{k-1}) \\
		 & \leq \sum_{k=1}^n A (x_k - x_{k-1})                \\
		 & = A (f(b) - f(a))
	\end{align*}
	Therefore, $f$ is of bounded variation on $[a, b]$.
\end{proof}

The following is a well crafted example of showing that
a continuous and differentiable function is not necessarily
of bounded variation
if we do not impose that its derivative is bounded in the interior.

\begin{example}
	Consider function defined on $[0, 1]$ given by
	\begin{align*}
		f(x) = \begin{cases}
			       x \cos \frac{\pi}{2x}, & x \in (0, 1] \\
			       0,                     & x = 0
		       \end{cases}
	\end{align*}
	Its graph is shown in Figure \ref{fig:2}.

	\begin{figure}[H]
		\centering
		\includegraphics[width=0.6\textwidth]{figures/continuous-function-that-is-not-of-bounded-variation.png}
		\caption{Graph of the function $f(x) = x \cos \frac{\pi}{2x}$ for $x \in (0, 1]$ and $f(0) = 0$. This function is continuous and its derivative exists in $(0, 1)$. But the derivative is unbounded.}
		\label{fig:2}
	\end{figure}

	The fact that this function is not of bounded variation may be less intuitive
	than the one given in Example~\ref{eg:1}.
	The function still varies rapidly near $x=0$.
	However, it does not range from $-1$ and $1$.
	Instead, it damps out at $x=0$ and becomes $0$.
	But we will show in the following that we can find a partition so fine that
	by collecting each small function variation,
	the overall sum may still increase to infinity.

	Consider the partition
	\begin{align*}
		P = \{0, \frac{1}{2n}, \frac{1}{2n - 1}, \dots, \frac{1}{3}, \frac{1}{2}, 1\}
	\end{align*}
	We have
	\begin{align*}
		\sum_k \abs{\Delta f_k}
		 & = \frac{1}{2n} + \frac{1}{2n} + \frac{1}{2n - 1} + \frac{1}{2n - 1}
		+ \dots + \frac{1}{2} + \frac{1}{2}                                    \\
		 & = 1 + \cdots + \frac{1}{n}
	\end{align*}
	As $n$ gets larger and larger,
	the sum on the right hand-side will increase infinitely
	for we know that the harmonic series $\sum \frac{1}{n}$ diverges.
	Therefore, this function is not of bounded variation.
\end{example}

Of course, the condition of the derivative being bounded is not necessary
for a function to be of bounded variation.

\begin{example}
	The derivative of the square root function $f(x) = \sqrt{x}$ in $(0, 1)$
	is $f^\prime(x) = \frac{1}{2\sqrt{x}}$,
	which tends to infinity as $x \to 0$.
	But $f$ is clearly of bounded variation on $[0, 1]$
	by Proposition~\ref{prop:1} for it is increasing.
\end{example}

Let $P$ be a partition of $[a, b]$.
If we make it finer by adding some intermediate points,
then the sum of variations will increase.
This result may be helpful in some proofs.

\begin{proposition} \label{prop:4}
	Let $f$ be defined on $[a, b]$,
	and $P$ a partition of $[a, b]$.
	If $P^\prime$ is finer than $P$, i.e., $P^\prime \supset P$,
	then
	\begin{align*}
		v(P^\prime, f) \geq v(P, f)
	\end{align*}
\end{proposition}

\begin{note}
	Compare this to the upper and lower Darboux sums
	when we introduce them in a later section.
\end{note}

\begin{proof}
	It suffices to that prove for the case
	where $P^\prime$ is one point finer than $P$.
	Suppose $P = \{x_0, \dots, x_n\}$ and $P^\prime = P \sqcup \{c\}$.
	We have
	\begin{align*}
		v(P^\prime, f)
		 & = \abs{f(x_1) - f(x_0)} + \cdots
		+ \abs{f(c) - f(x_{j-1})} + \abs{f(x_j) - f(c)} + \cdots
		+ \abs{f(x_n) - f(x_{n-1})}            \\
		 & \geq \abs{f(x_1) - f(x_0)} + \cdots
		+ \abs{f(x_j) - f(x_{j-1})} + \cdots
		+ \abs{f(x_n) - f(x_{n-1})}            \\
		 & = v(P, f)
	\end{align*}
	\begin{note}
		Note that $j$ may equal to $1$ or $n$ in the above notations.
		We write down the summation in the expanded form
		to make the proof easier to read.
	\end{note}
	This completes the proof.
\end{proof}

%------------------------------ 

\section{Total Variation}

Recall that $f$ is said to be of bounded of variation
on $[a, b]$ if, equivalently to what we stated, the set
\begin{align}
	\set{\sum_{k=1}^n \abs{\Delta f_k}}{P \in \CALP [a, b]}
	\label{eq:2}
\end{align}
or with our shortened notation
\begin{align*}
	\set{v(P, f)}{P \in \CALP[a, b]}
\end{align*}
is bounded above.
This set is of course nonempty for $\{a, b\}$ is clearly a partition.
By the least upper bound property,
the set in \eqref{eq:2} has a supremum, which is referred to as
\textbf{total variation}\index{total variation} of $f$ on $[a, b]$.

\begin{definition}
	Let $f$ be of bounded variation on $[a, b]$.
	The total variation, denoted by $V_a^b (f)$,
	of $f$ on $[a, b]$ is defined as
	\begin{align*}
		V_a^b (f)
		:= \sup_{P \in \CALP [a, b]} v(P, f)
		= \sup \set{\sum_{k=1}^n \abs{\Delta f_k}}{P \in \CALP [a, b]}
	\end{align*}
\end{definition}

\begin{note}
	We adopt the notation $V_a^b(f)$,
	which is inspired by the notion of
	a definite integral $\int_a^b f(x) \dif x$.
	And as we shall see,
	these two concepts indeed share some similar properties, namely,
	the linear properties.

	Notations are very important for they provide intuitive expressions
	of the intrinsic mathematical concepts.
\end{note}

From this definition,
we have some simple observations.
First, the value of $V_a^b (f)$ is nonnegative.
And it is easy to prove that $V_a^b (f) = 0$
if and only if $f$ is constant on $[a, b]$.

The simplest function of bounded variation
(well, apart from a constant function) is
monotonic function.
It is natural to ask what is its total variation.
With a little thought,
one can imagine that
it should be the absolute value of the difference at the endpoints.

\begin{proposition}
	If $f$ is a monotonic function on $[a, b]$,
	then its total variation is the absolute value of the difference
	of the function values at the endpoints, i.e.,
	\begin{align*}
		V_a^b(f) = \abs{f(a) - f(b)}
	\end{align*}
\end{proposition}

\begin{proof}
	We only prove the case that $f$ is increasing.
	For any partition $P = \{x_0, \dots, x_n\}$ of $[a, b]$, we have
	\begin{align*}
		\sum_{k=1}^n \abs{f(x_k) - f(x_{k-1})}
		= \sum_{k=1}^n [f(x_k) - f(x_{k-1})]
		= f(b) - f(a)
	\end{align*}
	Note that the sum is independent of the partition.
	Hence, the set in \eqref{eq:2} is just a constant.
	Therefore, the total variation $V_a^b(f) = f(b) - f(a)$.
\end{proof}

When studying functions of bounded variation,
in most cases, we are often interested in
monotonic functions
or continuous and differentiable functions.
(Proposition~\ref{prop:1} and \ref{prop:3}.)

\begin{note}
	On one hand, we will see in Theorem~\ref{thm:4},
	a function is of bounded variation if and only if
	it can be expressed as a difference
	of two increasing functions,
	the need of studying monotonic functions arises naturally.

	On the other hand, as we shall see in the chapter on Riemann-Stieltjes integrals,
	we assume the integrator $\alpha$ is of bounded variation.
	Since integrator $\alpha$ will be put after the
	differential operator, $\dif \alpha$,
	and we often hope to express it as $\alpha^\prime(t) \dif t$
	to reduce the integral to Riemann integral
	and compute its value,
	we would like $\alpha$ to be differentiable.
\end{note}

But if we are curious about whether some piecewise functions
are of bounded variation,
then Proposition~\ref{prop:1} and \ref{prop:3} will not be enough.

For example, consider the following function defined on $[0, 3]$:
\begin{align*}
	f(x) = \begin{cases}
		       x,           & 0 \leq x \leq 1 \\
		       -(x-1)(x-3), & 1 < x \leq 3
	       \end{cases}
\end{align*}
Figure~\ref{fig:4} depicts its graph.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\textwidth]{figures/piecewise-function-of-bounded-variation.png}
	\caption{Is this function of bounded variation on $[0, 3]$?}
	\label{fig:4}
\end{figure}

\begin{theorem} \label{thm:1}
	Let $f$ and $g$ be of bounded variation on $[a, b]$, then
	so are their sum, difference and product.
	Moreover, we have the following inequalities:
	\begin{align}
		V_a^b (f \pm g)  \leq V_a^b (f) + V_a^b (g)
		\label{eq:3}
	\end{align}
	and
	\begin{align}
		V_a^b (fg)       \leq \sup_{x \in [a, b]} \abs{g(x)} V_a^b (f)
		+ \sup_{x \in [a, b]} \abs{f(x)} V_a^b (g)
		\label{eq:4}
	\end{align}
\end{theorem}

\begin{note}
	Note that the supremums in \eqref{eq:4} indeed exist
	since the functions $f$ and $g$ are bounded due to Proposition~\ref{prop:2}.
\end{note}

\begin{proof}
	We first show that the sum and the difference of two functions
	are of bounded variation, and satisfy \eqref{eq:3}.
	Let $P$ be an arbitrary partition of $[a, b]$.
	On each subinterval, we have
	\begin{align*}
		\abs{\Delta (f \pm g)_k}
		 & = \abs{f(x_{k}) \pm g(x_{k}) - [f(x_{k-1}) \pm g(x_{k-1})]} \\
		 & = \abs{\Delta f_k \pm \Delta g_k}                           \\
		 & \leq \abs{\Delta f_k} + \abs{\Delta g_k}
	\end{align*}
	Taking the sum over $k$, we have
	\begin{align*}
		\sum_{k} \abs{\Delta (f \pm g)_k}
		\leq \sum_{k} \abs{\Delta f_k} + \sum_k \abs{\Delta g_k}
		\leq V_a^b (f) + V_a^b (g)
	\end{align*}
	The above inequality shows that $f \pm g$ is of bounded variation on $[a, b]$,
	and \eqref{eq:3} is satisfied.

	In the following, we show that the product of two Functions
	are of bounded variation and satisfies \eqref{eq:4}.
	Let $P$ be an arbitrary partition of $[a, b]$.
	On each subinterval, we have
	\begin{align*}
		\abs{\Delta (fg)_k}
		 & = \abs{f(x_{k}) g(x_{k}) - f(x_{k-1}) g(x_{k-1})}                                \\
		 & \text{Add and subtract the term $f(x_{k-1})g(x_{k})$}                            \\
		 & = \abs{ g(x_{k})[ f(x_{k}) - f(x_{k-1})] + f(x_{k-1})[ g(x_{k}) - g(x_{k-1}) ] } \\
		 & \leq \abs{g(x_{k})} \abs{\Delta f_k} + \abs{f(x_{k-1})} \abs{ \Delta g_k }       \\
		 & \leq \sup_{x \in [a, b]} \abs{g(x)} \abs{\Delta f_k}
		+ \sup_{x \in [a, b]} \abs{f(x)} \abs{\Delta g_k}
	\end{align*}
	Summing over $k$, we have
	\begin{align*}
		\sum_k \abs{\Delta (fg)_k}
		\leq \sup_{x \in [a, b]} \abs{g(x)} \sum_k \abs{\Delta f_k}
		+ \sup_{x \in [a, b]} \abs{f(x)} \sum_k \abs{\Delta g_k} \\
		\leq  \sup_{x \in [a, b]} \abs{g(x)} V_a^b (f)
		+ \sup_{x \in [a, b]} \abs{f(x)} V_a^b (g)
	\end{align*}
	This shows the product $fg$ is in fact of bounded variation on $[a, b]$,
	and \eqref{eq:4} is satisfied.
\end{proof}

We must exclude the quotients from the above theorem
since the reciprocal $\frac{1}{f}$ of $f$ may not be of bounded variation
even though $f$ is.

\begin{example}
	Consider function
	\begin{align*}
		f(x) = \begin{cases}
			       1-x, & 0 \leq x < 1     \\
			       -x,  & 1 \leq x  \leq 2
		       \end{cases}
	\end{align*}
	Function $f$ is of bounded variation on $[0, 2]$ since it is decreasing.
	Its reciprocal is
	\begin{align*}
		\frac{1}{f(x)} = \begin{cases}
			                 \frac{1}{1-x}, & 0 \leq x < 1     \\
			                 -\frac{1}{x},  & 1 \leq x  \leq 2
		                 \end{cases}
	\end{align*}
	Figure \ref{fig:3} depicts the graphs of $f$ and $\frac{1}{f}$.
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.6\textwidth]{figures/reciprocal-not-of-bounded-variation.png}
		\caption{Left: $f$ is of bounded variation for it is decreasing. Right: $\frac{1}{f}$ is not of bounded variation for it is unbounded.}
		\label{fig:3}
	\end{figure}
	Note that $\frac{1}{f}$ goes to positive infinity when $x \to 1^-$.
	Therefore, by Proposition~\ref{prop:2}, $\frac{1}{f}$ is not of bounded variation on $[0, 2]$
	since it is not bounded.
\end{example}

To extend Theorem~\ref{thm:1} to quotients,
we need to required that $f$ is bounded away from zero in the interval.

\begin{theorem}
	Let $f$ be of bounded variation on $[a, b]$.
	And there exists $m > 0$ such that $f(x) \geq m$ for all $x \in [a, b]$.
	Then the reciprocal of $f$ is of bounded variation on $[a, b]$, and
	\begin{align*}
		V_a^b ( \frac{1}{f} )
		\leq \frac{1}{m^2} V_a^b (f)
	\end{align*}
\end{theorem}

\begin{proof}
	Let $P$ be any partition of $[a, b]$.
	On each subinterval $[x_{k-1}, x_k]$, we have
	\begin{align*}
		\abs{\Delta (\frac{1}{f})_k}
		 & = \abs{\frac{1}{f(x_k)} - \frac{1}{f(x_{k-1})}} \\
		 & = \abs{\frac{\Delta f_k}{f(x_{k-1}) f(x_k)}}    \\
		 & \leq \frac{\abs{ \Delta f_k }}{m^2}
	\end{align*}
	Summing over $k$, we have
	\begin{align*}
		\sum_k \abs{\Delta (\frac{1}{f})_k}
		\leq \frac{1}{m^2} \sum_k \abs{\Delta f_k}
		\leq \frac{1}{m^2} V_a^b (f)
	\end{align*}
	Therefore, $\frac{1}{f}$ is of bounded variation on $[a, b]$.
\end{proof}

\subsection{Additive Property of Total Variation}

\begin{theorem} \label{thm:2}
	Let $f$ be of bounded variation on $[a, b]$, and $c \in (a, b)$.
	Then $f$ is of bounded variation on the subintervals $[c, b]$ and $[a, c]$.
	Moreover, we have
	\begin{align}
		V_a^b(f) = V_a^c(f) + V_c^b(f)
		\label{eq:9}
	\end{align}
\end{theorem}

\begin{proof}
	We will first show that $f$ is of bounded variation on each subinterval, and
	\begin{align}
		V_a^c(f) + V_c^b(f) \leq V_a^b(f)
		\label{eq:5}
	\end{align}

	Let $P^\prime$ and $P^{\prime\prime}$ be partitions of $[a, c]$ and $[c, b]$,
	respectively,
	and let $P = P^\prime \cup P^{\prime\prime}$.
	Note that $P$ is a partition of $[a, b]$,
	and by reviewing the notation of $v(P, f)$
	one may easily conclude that $v(P^\prime, f) + v(P^{\prime\prime}, f) = v(P, f)$.
	Since $f$ is of bounded of variation on $[a, b]$, we have
	\begin{align}
		v(P^\prime, f) + v(P^{\prime\prime}, f) = v(P, f) \leq V_a^b (f)
		\label{eq:6}
	\end{align}
	The above inequality holds for any partition $p^\prime$ of $[a, c]$
	and any partition $P^{\prime\prime}$ of $[c, b]$.
	Therefore, by definition, $f$ is of bounded variation on $[a, c]$ and $[c, b]$.
	Moreover, taking the supremum over $P^\prime$ and then over $P^{\prime\prime}$
	on both sides of \eqref{eq:6}, we will obtain exactly \eqref{eq:5}.

	To show the equality \eqref{eq:9}, we also need to show
	\begin{align}
		V_a^c(f) + V_c^b(f) \geq V_a^b (f)
		\label{eq:7}
	\end{align}
	Let $\varepsilon > 0$ be arbitrary.
	There exists a partition $P$ of $[a, b]$
	such that $v(P, f) > V_a^b(f) - \varepsilon$.
	Let
	\begin{align*}
		P^\prime = ( P \cap [a, c] ) \cup \{c\} \quad \text{and} \quad
		P^{\prime\prime} = ( P \cap [c, b] ) \cup \{c\}
	\end{align*}
	It is clear that $P^\prime$ and $P^{\prime\prime}$
	are partitions of $[a, c]$ and $[c, b]$, respectively.
	By Proposition~\ref{prop:4}, we have
	\begin{align}
		V_a^c(f) + V_c^b(f) \geq v(P^\prime, f)
		+ v(P^{\prime\prime}, f)
		\geq v(P, f) > V_a^b(f) - \varepsilon
		\label{eq:8}
	\end{align}
	Because \eqref{eq:8} holds for every $\varepsilon > 0$, \eqref{eq:7} is proved.
\end{proof}

Applying the above theorem, we can immediately conclude that $f$
is also of bounded variation on any interval contained in $[a, b]$.

\begin{corollary} \label{cor:1}
	If $f$ is of bounded variation on $[a, b]$,
	and $[c, d] \subseteq [a, b]$,
	then $f$ is also of bounded variation on $[c, d]$.
\end{corollary}

\begin{proof}
	With the given condition, we have $a \leq c < d \leq b$.
	If $c = a$ or $d = b$,
	then the assumption of this corollary reduces to the one in Theorem~\ref{thm:2}.

	Now, we assume that $a < c < d <b$.
	Regarding $c$ as an intermediate point in $[a, b]$,
	Theorem~\ref{thm:2} shows that $f$ is of bounded variation on $[c, b]$.
	Next, because $d \in (c, b)$, applying Theorem~\ref{thm:2} again,
	we conclude that $f$ is of bounded variation on $[c, d]$.
\end{proof}

\subsection{Total Variation as a Function of the Right Endpoint}

Suppose $f$ is of bounded variation on $[a, b]$.
For any $x \in (a, b)$.
Theorem~\ref{thm:2} tells us that $f$ is of bounded variation on $[a, x]$.
Therefore, we can regard $V_a^x (f)$ as a function of $x$.

\begin{note}
	This is very similar to considering $\int_a^x f(t) \dif t$ as a function
	of the upper limit of the integral, which
	again shows that our notation of the total variation rather helpful.
\end{note}

When $x = b$, it is just the total variation of $f$ on the entire interval.
We don't have definition for $x = a$ yet.
But we can easily fix this by naturally defining $V_a^a (f) := 0$.
Now, function $V_a^x(f)$ is defined on the entire interval $[a, b]$.

In the next chapter, we will study the Riemann-Stieltjes integral, which
is more generalized definition of the Riemann integral.
In the texts of the Riemann-Stieltjes integral $\int_a^b f \dif \alpha$,
we often assume that the integrator $\alpha$ is increasing
(or slightly more generalized, monotonic)\cite{rudinPrinciplesMathematicalAnalysis1976}.
But we can extend the results easily to a even more
general assumption that the integrator $\alpha$
is of bounded variation on $[a, b]$.

The key of achieving this is that a function of bounded variation
can be written as a difference of two increasing functions,
and conversely, the difference of two increasing functions
is of bounded variation
(Theorem~\ref{thm:4}).
And the following theorem tells us exactly how to
find such increasing
functions.

\begin{theorem} \label{thm:3}
	Let $f$ be of bounded variation on $[a, b]$.
	Then
	\begin{enumerate}
		\item $V_a^x(f)$ is increasing on $[a, b]$, and
		\item $V_a^x(f) - f(x)$ is also increasing.
	\end{enumerate}
\end{theorem}

\begin{proof}
	Let $h > 0$ (and $x + h \leq b$), by Theorem~\ref{thm:2}, we have
	\begin{align*}
		V_a^x (f) + V_x^{x+h} (f) = V_a^{x+h} (f)
	\end{align*}
	\begin{note}
		We have seen in Corollary~\ref{cor:1} that $V_x^{x+h}(f)$ indeed exists.
	\end{note}
	It then follows that
	\begin{align*}
		V_a^{x+h}(f) - V_a^{x}(f) = V_x^{x+h}(f) \geq 0
	\end{align*}
	This shows $V_a^x(f)$ is increasing.

	Next, we will prove $V_a^x(f) - f(x)$ is creasing.
	To ease the notation, let $g(x) = V_a^x(f) - f(x)$.
	Similarly, suppose $h > 0$ and $x + h \leq b$,
	consider the difference
	\begin{align}
		g(x+h) - g(x)
		= V_x^{x+h}(f) + [f(x+h) - f(x)]
		\label{eq:10}
	\end{align}
	\begin{note}
		Seeing the term $f(x+h) - f(x)$ in the context of total variation,
		we immediately think of the partition $P = \{x, x+h\}$ of $[x, x+h]$.
	\end{note}
	We have
	\begin{align*}
		\abs{f(x+h) - f(x)} \leq V_x^{x+h}(f)
	\end{align*}
	It then follows that
	\begin{align*}
		V_x^{x+h}(f) \geq \abs{f(x+h) - f(x)} \geq -[f(x+h) - f(x)]
	\end{align*}
	which further implies
	\begin{align}
		V_x^{x+h}(f) + [f(x+h) - f(x)] \geq 0
		\label{eq:11}
	\end{align}
	Comparing \eqref{eq:10} and \eqref{eq:11}, we conclude
	that $g(x)$ is indeed increasing.
\end{proof}

\subsection{Characterization of Functions of Bounded Variation}

With the help of Theorem~\ref{thm:3}, we can easily prove
the following elegant theorem,
which characterizes functions of bounded variation.
It states that a function on $[a, b]$ is of bounded variation
if and only if it can be written as a difference of two increasing functions.
The difficult part of find such increasing functions
is already handled by Theorem~\ref{thm:3}.

\begin{theorem} \label{thm:4}
	Let $f$ be defined on $[a, b]$,
	then $f$ is of bounded variation if and only if
	it can be expressed as a difference of two
	increasing functions.
\end{theorem}

\begin{proof}
	We first suppose that $f$ is of bounded variation.
	Then Theorem~\ref{thm:3} shows that $V_a^x(f)$
	and $V_a^x(f) - f(x)$ are both increasing on $[a, b]$.
	Since we can write
	\begin{align*}
		f(x) = V_a^x(f) - [ V_a^x (f) - f(x)]
	\end{align*}
	It is proved.

	Reversely, suppose that $f$ can be expressed as a difference of
	two increasing functions $g$ and $h$ on $[a, b]$, $f = g - h$.
	Proposition~\ref{prop:1} tells us that $g$ and $h$ are of bounded variation
	since they are increasing functions.
	Then by Theorem~\ref{thm:1}, we know that $g - h$ is also of bounded variation.
	This completes the proof.
\end{proof}

\begin{note}
	We can also make these two increasing functions strict.
	Suppose $f = g - h$.
	We can easily achieve this by defining $\tilde{g}(x) = g(x) + x$
	and $\tilde{h}(x) = h(x) + x$.
\end{note}




%==============================

% References
\printbibliography[heading=bibintoc, title=References]

%==============================

% Print index page
\printindex

\end{document}
